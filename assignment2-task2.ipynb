{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1535376-2807-4bca-98d6-9e9519003015",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.018674Z",
     "end_time": "2023-04-25T14:14:16.031638Z"
    }
   },
   "outputs": [],
   "source": [
    "### in this task missing values *should be imputed* with the mean value of the column\n",
    "### impute missing values only in columns required for solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8255ea1-d3e9-4fbd-90b1-02d0ff7b7f9e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.032636Z",
     "end_time": "2023-04-25T14:14:16.046213Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 20, 'figure.figsize': (8, 4)})\n",
    "\n",
    "#%matplotlib inline\n",
    "#import matplotlib_inline\n",
    "#matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02062230-22bd-45bd-99c6-bf8a79bfcc2d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.048209Z",
     "end_time": "2023-04-25T14:14:16.084039Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_books_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Data correction and imputation:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.080018Z",
     "end_time": "2023-04-25T14:14:16.096391Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Weight imputation:\n",
    "df['weight'] = df['weight'].map(lambda x: float(str(x)[:-6]) * (1/16) if str(x).endswith('ounces') else float(str(x)[:-6]), na_action='ignore')\n",
    "mean = df['weight'].mean()\n",
    "df['weight'].fillna(mean, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.095394Z",
     "end_time": "2023-04-25T14:14:16.167768Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Pages imputation:\n",
    "mean = round(df['pages'].mean())\n",
    "df['pages'].fillna(mean, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.127783Z",
     "end_time": "2023-04-25T14:14:16.182690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Volume imputation\n",
    "def get_volume(dimensions):\n",
    "    dimensions = str(dimensions)[:-6]\n",
    "    dimensions = dimensions.split('x')\n",
    "    volume = 1.0\n",
    "    for length in dimensions:\n",
    "        volume *= float(length)\n",
    "    return float(volume)\n",
    "\n",
    "df['volume'] = df['dimensions'].map(get_volume, na_action='ignore')\n",
    "mean = df['volume'].mean()\n",
    "df['volume'].fillna(mean, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.147721Z",
     "end_time": "2023-04-25T14:14:16.183687Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Price imputation:\n",
    "mean = df['price'].mean()\n",
    "df['price'].fillna(mean, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.172716Z",
     "end_time": "2023-04-25T14:14:16.197219Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4c919712-dccb-4dbc-8e3d-baa0f3d0e4b2",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c51667-303d-4ae5-a449-bc61d58f1b13",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.189227Z",
     "end_time": "2023-04-25T14:14:16.222907Z"
    }
   },
   "outputs": [],
   "source": [
    "### decide what data type each column is: numerical-discrete, numerical-continuous, categorical-nominal, categorical-ordinal\n",
    "### consider only [price, pages, avg_reviews, n_reviews, language] for this analysis\n",
    "### no need to add explanations, just the final answer\n",
    "\n",
    "# Final answer:\n",
    "# price - numerical-continuous\n",
    "# pages - numerical-discrete\n",
    "# avg_reviews - numerical-continuous\n",
    "# n_reviews - numerical-discrete\n",
    "# language - categorical-nominal\n",
    "\n",
    "answer_list = [('price', 'numerical-continuous'), ('pages', 'numerical-discrete'), ('avg_reviews', 'numerical-continuous'), ('n_reviews', 'numerical-discrete'), ('language', 'categorical-nominal')]\n",
    "answer_df = pd.DataFrame(answer_list, columns=['Column', 'Type'])\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165920b1-0135-4593-a162-8d4eba529990",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ba3ec-c639-4589-bbd7-3f3449d31829",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.219919Z",
     "end_time": "2023-04-25T14:14:16.277072Z"
    }
   },
   "outputs": [],
   "source": [
    "### compute Pearson's correlation between pages and weight in the data\n",
    "### (you can use the built-in Series.corr() function for that purpose)\n",
    "answer_df = pd.DataFrame([('Correlation', df['pages'].corr(df['weight']))])\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc58e4a-c25d-4267-b319-93891138bd5f",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c2046-fdd2-44e8-bd7b-0f6c4e191833",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.251246Z",
     "end_time": "2023-04-25T14:14:16.671570Z"
    }
   },
   "outputs": [],
   "source": [
    "### show a scatter plot of pages (x) and weight (y)\n",
    "### do the results fit the score you got in the previous cell? (no need to print answer to this question)\n",
    "df[['pages', 'weight']].plot.scatter(x='pages', y='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c9477-1a20-4962-9289-3dc593dd4ca5",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb0cdb7-8b3d-4a84-b30c-e59df8797135",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.678034Z",
     "end_time": "2023-04-25T14:14:16.754232Z"
    }
   },
   "outputs": [],
   "source": [
    "### compute Pearson's correlation between a book's volume (inferred by its dimensions) and price in the data\n",
    "### (you can use the built-in Series.corr() function for that purpose)\n",
    "answer_df = pd.DataFrame([('Correlation', df['volume'].corr(df['price']))])\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59426d-26d0-4110-bdc1-fafe3157edb7",
   "metadata": {},
   "source": [
    "#### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd71993-a837-4a79-82c4-06bc67ac2c38",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.702129Z",
     "end_time": "2023-04-25T14:14:16.994700Z"
    }
   },
   "outputs": [],
   "source": [
    "### show a scatter plot of a book's volume (inferred by its dimensions) and price\n",
    "### do the results fit the score you got in the previous cell? (no need to print answer to this question)\n",
    "df[['volume', 'price']].plot.scatter(x='volume', y='price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea8fab2-2945-43df-b35d-9853c1afb669",
   "metadata": {},
   "source": [
    "#### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d891df9-7692-4952-a2b9-45c91038ad20",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:16.969754Z",
     "end_time": "2023-04-25T14:14:17.013160Z"
    }
   },
   "outputs": [],
   "source": [
    "### inspect book titles carefully: they can be roughly split by keyphrases:\n",
    "### ['data science', 'data analytics', 'data engineering', 'machine learning', 'statistics', \n",
    "### 'deep learning', 'natural language processing']\n",
    "\n",
    "### a book belongs to one of the above categories if its name contains the corresponding keyphrase\n",
    "### display the number of books that fall into each category and their total, in the same table\n",
    "### some books may not belong to any of the listed above categories\n",
    "\n",
    "key_phrases = ['data science', 'data analytics', 'data engineering', 'machine learning', 'statistics', 'deep learning', 'natural language processing']\n",
    "df['title'] = df['title'].apply(lambda x: str(x).lower())\n",
    "df['category'] = df['title'].apply(lambda x: [key_phrase for key_phrase in key_phrases if key_phrase in x])\n",
    "key_counts = list()\n",
    "for key_phrase in key_phrases:\n",
    "    df[key_phrase] = df['category'].apply(lambda x: 1 if key_phrase in x else 0)\n",
    "    key_counts.append((key_phrase, len(df[df[key_phrase] == 1])))\n",
    "\n",
    "total = len(df[df['category'].apply(lambda x: len(x) > 0)])\n",
    "key_counts.append(('Total', total))\n",
    "\n",
    "answer_df = pd.DataFrame(key_counts, columns=['Key Phrase', 'Count'])\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f0ced-0fec-4ffa-a490-81dc78899680",
   "metadata": {},
   "source": [
    "#### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403786ac-bcad-4b79-af8c-37e2885deb78",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:17.014158Z",
     "end_time": "2023-04-25T14:14:17.117353Z"
    }
   },
   "outputs": [],
   "source": [
    "### display the same result where the dataframe is sorted by the number of books, descending\n",
    "### no need to display the total amount in this result - drop it\n",
    "answer_df = answer_df.sort_values(by='Count', ascending=False)\n",
    "answer_df = answer_df.drop(index=7)\n",
    "answer_df.reset_index(drop=True, inplace=True)\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877ac449-b9cd-425e-873f-74e93dcfda45",
   "metadata": {},
   "source": [
    "#### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c6e631-a9de-49e9-95e7-c919bf789c90",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:24:07.040020Z",
     "end_time": "2023-04-25T14:24:07.073866Z"
    }
   },
   "outputs": [],
   "source": [
    "### sample 10000 values from N~(10, 5)\n",
    "### for this purpose use https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html\n",
    "\n",
    "### what portion of the distribution is found in the range (2.5, 17.5)? -- calculate using z table\n",
    "### (recall the NormalDist().cdf() function we used at the lecture)\n",
    "\n",
    "### what portion of the distribution is found in the range (2.5, 17.5)? -- compute empirically using the sampled values\n",
    "### report both values (calculated and empirical)\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "\n",
    "# taking 10,000 samples of the above normal distribution\n",
    "samples = np.random.normal(10, 5, 10000)\n",
    "# calculating the portion of the distribution in the range (2.5, 17.5)\n",
    "prob_portion = st.NormalDist(10, 5).cdf(17.5) - st.NormalDist(10, 5).cdf(2.5)\n",
    "# calculating the portion of the distribution in the range (2.5, 17.5) empirically\n",
    "empirical_portion = len([sample for sample in samples if 2.5 < sample < 17.5]) / len(samples)\n",
    "\n",
    "answer_df = pd.DataFrame([('Z-table calculated', prob_portion), ('Empirical', empirical_portion)], columns=['Method', 'Portion'])\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f2b66-dc90-4c54-9499-66c46e3a192f",
   "metadata": {},
   "source": [
    "#### Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca084c9-3a03-4219-9530-8bc6437a7a70",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:32:02.227644Z",
     "end_time": "2023-04-25T14:32:02.252344Z"
    }
   },
   "outputs": [],
   "source": [
    "### compute confidence interval of 95% for the true population mean of a book price on Amazon\n",
    "### report left and right boundaries\n",
    "mean, std, n = df['price'].mean(), df['price'].std(), len(df['price'])\n",
    "alpha = 0.05\n",
    "z = st.NormalDist().inv_cdf(1 - alpha / 2)\n",
    "left, right = mean - z * std / np.sqrt(n), mean + z * std / np.sqrt(n)\n",
    "\n",
    "answer_df = pd.DataFrame([('Left', left), ('Right', right)], columns=['Boundary', 'Value'])\n",
    "answer_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a077478-b75e-4592-ae78-745678fa0820",
   "metadata": {},
   "source": [
    "#### Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa994a1-d98f-4b12-aabf-9af310b49523",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:14:17.058625Z",
     "end_time": "2023-04-25T14:14:17.118351Z"
    }
   },
   "outputs": [],
   "source": [
    "### can one say with (at least) 85% confidence that the true population mean of a book price resides within the [50.0, 53.0] interval?\n",
    "### show your computations, and print your answer: yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecf6e4-e36c-4277-ad73-034421c088ae",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T14:50:35.392214Z",
     "end_time": "2023-04-25T14:50:35.433198Z"
    }
   },
   "outputs": [],
   "source": [
    "left_z = st.NormalDist().cdf((50 - mean) / (std / np.sqrt(n)))\n",
    "right_z = st.NormalDist().cdf((53 - mean) / (std / np.sqrt(n)))\n",
    "portion = right_z - left_z\n",
    "\n",
    "answer_df = pd.DataFrame([('Answer', 'yes' if portion >= 0.85 else 'no')])\n",
    "answer_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
